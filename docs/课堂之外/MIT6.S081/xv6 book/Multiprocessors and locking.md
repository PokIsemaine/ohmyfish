# Multiprocessors and locking

## 问题关联图



## 梳理

注：本章主要讨论用锁处理多 CPU 共享内存产生的问题，多线程暂时不是重点



## 问题 1 为什么需要锁？

**多处理器层面**

多个处理器共享物理内存，xv6利用共享（sharing）来维护所有CPU进行读写的数据结构。这导致同一时间可能有多方对同一块内存进行读写操作，在没有特殊处理的情况下，这种并行访问可能会产生不正确的结果或损坏数据结构。**锁就是用来确保这种情况下的正确性**

![image-20220712134849982](https://s2.loli.net/2022/07/12/XbDEUwn6HkzuNVA.png)

**单处理器层面**

多线程共享内存，存在同样的问题



### 为什么要多核？

应用程序想靠多核并行来加速，内核想要并行处理系统调用



**单靠单核多线程不行吗？**

![image-20220712000345648](https://s2.loli.net/2022/07/12/byA4tO1QkFR9jxK.png)

2010 年开始

- CPU的时钟频率就没有再增加过了（绿线）这意味着，CPU的单线程性能达到了一个极限并且也没有再增加过（蓝线）。
- 但是另一方面，CPU中的晶体管数量在持续的增加 （深红色线）。
- 所以现在不能通过使用单核来让代码运行的更快，要想运行的更快，唯一的选择就是使用多个CPU核。所以从2000年开始，处理器上核的数量开始在增加（黑线）。

所以现在如果一个应用程序想要提升性能，它不能只依赖单核，必须要依赖于多核。这也意味着，如果应用程序与内核交互的较为紧密，那么操作系统也需要高效的在多个CPU核上运行



### 为什么未经设计的并行读写会出问题 ？

**竞态条件**

竞态条件指的是两个或者以上进程或者线程并发执行时，其最终的结果依赖于进程或者线程执行的精确时序

**案例1 hashtabel**

![image-20220712001619889](https://s2.loli.net/2022/07/12/KP95zrOaN3sRVqb.png)

![image-20220712135143785](https://s2.loli.net/2022/07/12/mBZNjohSE9fRkub.png)

![image-20220712135213977](https://s2.loli.net/2022/07/12/l32XzCyFir1wxhG.png)



**案例2 kfree**

![img](http://xv6.dgs.zone/tranlate_books/book-riscv-rev1/images/c6/p1.png)



**锁如何消除竞态条件？**

锁提供了两个 API

* acquire，接收指向lock的指针作为参数。acquire确保了在任何时间，只会有一个进程能够成功的获取锁。
* release，也接收指向lock的指针作为参数。在同一时间尝试获取锁的其他进程需要等待，直到持有锁的进程对锁调用release。

acquire 和 release 之间的代码形成 critical section （临界区）

临界区中运行的代码在同一时间只允许一个进程运行，并且整个临界区域的代码运行是原子的，要么完整运行要么不运行

也就是说锁将临界区代码由原来的并发执行改为串行化了，这样就消除了竞态条件



**如何自动检测竞态条件？**

借助一些 race-detection 工具来检测竞态条件

google/sanitizers 提供的 ThreadSanitizer 中包含竞态检测 https://github.com/google/sanitizers/wiki/ThreadSanitizerDetectableBugs

Valgrind 的 Helgrind 也提供了数据争用的检测  https://valgrind.org/docs/manual/hg-manual.html#hg-manual.data-races



### 锁的作用？

* 使用锁来协调对于共享数据的更新，以确保数据的一致性

* 使用锁可以避免丢失更新
* 锁可以打包多个操作，使它们具有原子性
* 锁可以维护共享数据结构的不变性，共享数据结构如果不被任何进程修改的话是会保持不变的



### 回答梳理



## 问题 2 如何使用锁 ？

一把大锁保平安可能导致的问题

* 并发度和性能下降
* 降低模块化程度
	* 锁使得隐藏模块内部的细节变得困难 ，例如：为了避免死锁，您必须知道每个函数获取了哪些锁 •
	*  锁不一定是每个单独模块的私有业务 ，过多的抽象会导致难以编写 正确，性能良好的锁定



### 什么时候加锁？

**保守但够用的原则**：如果两个进程访问了一个共享的数据结构，并且其中一个进程会更新共享的数据结构，那么就需要对于这个共享的数据结构加锁。

在有时候这个原则可能太严格了，对于 lock-free program，不加锁也可以获得正常运行，不过这有一定难度。



### 在哪里插入和释放锁？

自顶向下策略

1. 先保证写的每个模块在串行情况下是正确的
2. 然后通过加锁来强制串行化

自底向上策略

1. 观察数据结构
2. 问自己这个数据是否需要被共享
3. 如果被共享再问自己哪个锁来保护对它的访问



### 上锁能够自动吗？

既然锁可以消除竞态条件，那么可以自动化加锁吗？

考虑如果要实现上锁自动化我们可以怎么做？

 race-detection 工具来检测竞态条件，然后给每个存在竞争条件的数据结构做个封装，每次操作的时候自动加锁，这在技术层面似乎是可行的

不过如果真这样做好像有些太严格了，过度防护了！



另外，课程中也给了一个反例

> 假设我们有一个对于rename的调用，这个调用会将文件从一个目录移到另一个目录，我们现在将文件d1/x移到文件d2/y。
>
> 如果我们按照前面说的，对数据结构自动加锁。现在我们有两个目录对象，一个是d1，另一个是d2，那么我们会先对d1加锁，删除x，之后再释放对于d1锁；之后我们会对d2加锁，增加y，之后再释放d2的锁。这是我们在使用自动加锁之后的一个假设的场景。
>
> 在这个例子中，我们会有错误的结果，那么为什么这是一个有问题的场景呢？为什么这个场景不能正常工作？
>
> 在我们完成了第一步，也就是删除了d1下的x文件，但是还没有执行第二步，也就是创建d2下的y文件时。其他的进程会看到什么样的结果？是的，其他的进程会看到文件完全不存在。这明显是个错误的结果，因为文件还存在只是被重命名了，文件在任何一个时间点都是应该存在的。但是如果我们按照上面的方式实现锁的话，那么在某个时间点，文件看起来就是不存在的。
>
> 所以这里正确的解决方法是，我们在重命名的一开始就对d1和d2加锁，之后删除x再添加y，最后再释放对于d1和d2的锁。 

在这个例子中，我们的操作需要涉及到多个锁，但是直接为每个对象自动分配一个锁会带来错误的结果。在这个例子中，锁应该与操作而不是数据关联，所以自动加锁在某些场景下会出问题。



**所以上锁这件事目前来说应当由程序员自己来设计**



### 释放锁能自动吗？

忘记释放锁是并发编程中常见的错误，那么可不可以在对象出作用域的时候自动释放锁呢？

在C++ 中，可以通过 RAII 技术来实现 范围锁，在对象出作用域的时候调用析构函数自动持有的锁

如果你不想自己实现的话可以采用标准库提供的

[std::lock_guard](https://en.cppreference.com/w/cpp/thread/lock_guard)

[std::scoped_lock](https://en.cppreference.com/w/cpp/thread/scoped_lock)

[std::unique_lock](https://en.cppreference.com/w/cpp/thread/unique_lock)

[std::shared_lock](https://en.cppreference.com/w/cpp/thread/shared_lock)



### 锁的粒度

由于锁会将临界区代码强制串行化，所以锁的粒度会影响到模块的性能



粗粒度锁的一个例子，xv6的`kalloc.c`分配器有一个由单个锁保护的空闲列表。如果不同CPU上的多个进程试图同时分配页面，每个进程在获得锁之前将必须在`acquire`中自旋等待。自旋会降低性能，因为它只是无用的等待。如果对锁的争夺浪费了很大一部分CPU时间，也许可以通过改变分配器的设计来提高性能，使其拥有多个空闲列表，每个列表都有自己的锁，以允许真正的并行分配。



细粒度锁的一个例子，xv6对每个文件都有一个单独的锁，这样操作不同文件的进程通常可以不需等待彼此的锁而继续进行。文件锁的粒度可以进一步细化，以允许进程同时写入同一个文件的不同区域。



策略

1. 先给每个模块一把大锁保平安
2. 测量性能，看是否存在性能问题
3. 如果存在严重的性能问题，不得不重新设计再去考虑修改



一定要测试过，用数据把问题暴露出来再去决定是否重新设计，**最终的锁粒度决策需要由性能测试和复杂性考量来驱动。**



> 过早优化是万恶之源	--- Donald Knuth



### 如何优化锁竞争？

锁竞争优化一般有几个思路：

- 只在必须共享的时候共享（对应为将资源从 CPU 共享拆分为每个 CPU 独立）
- 必须共享时，尽量减少在关键区中停留的时间（对应“大锁化小锁”，降低锁的粒度）



brpc 中的 bvar 通过避免共享来优化计数器（可以聊聊）

https://github.com/apache/incubator-brpc/blob/master/docs/cn/atomic_instructions.md#cacheline



### 问题 3 关于死锁

一个死锁的最简单的场景就是：首先acquire一个锁，然后进入到critical section；在critical section中，再acquire同一个锁；第二个acquire必须要等到第一个acquire状态被release了才能继续执行，但是不继续执行的话又走不到第一个release，所以程序就一直卡在这了。这就是一个死锁。

![image-20220712165924110](https://s2.loli.net/2022/07/12/yXqP1FNGRzuktgY.png)

```c

```



### 死锁的类型？



### 如何预防死锁？

 race-detection 工具来检测死锁



### 死锁的解决方案？

这里给出课程里的解决方案：如果你有多个锁，你需要对锁进行排序，所有的操作都必须以相同的顺序获取锁



遵守全局死锁避免的顺序可能会出人意料地困难。有时锁顺序与逻辑程序结构相冲突，例如，也许代码模块M1调用模块M2，但是锁顺序要求在M1中的锁之前获取M2中的锁。有时锁的身份是事先不知道的，也许是因为必须持有一个锁才能发现下一个要获取的锁的身份。这种情况在文件系统中出现，因为它在路径名称中查找连续的组件，也在`wait`和`exit`代码中出现，因为它们在进程表中寻找子进程。最后，死锁的危险通常是对细粒度锁定方案的限制，因为更多的锁通常意味着更多的死锁可能性。避免死锁的需求通常是内核实现中的一个主要因素。



一种想法：**通过锁的地址来强制锁的顺序**

> from OSTEP
>
> 提示：通过锁的地址来强制锁的顺序 当一个函数要抢多个锁时，我们需要注意死锁。比如有一个函数：do_something(mutex t *m1, mutex t *m2)，
>
> 如果函数总是先抢 m1，然后 m2，那么当一个线程调用 do_something(L1, L2)，而另一个线程调 用 do_something(L2, L1)时，就可能会产生死锁。 为了避免这种特殊问题，聪明的程序员根据锁的地址作为获取锁的顺序。
>
> 按照地址从高到低，或者 从低到高的顺序加锁，do_something()函数就可以保证不论传入参数是什么顺序，函数都会用固定的顺 序加锁。
>
> 具体的代码如下：
>
> ```c
> if (m1 > m2) { // grab locks in high-to-low address order
>     pthread_mutex_lock(m1);
>     pthread_mutex_lock(m2);
> } else {
>     pthread_mutex_lock(m2);
>     pthread_mutex_lock(m1);
> }
> // Code assumes that m1 != m2 (it is not the same lock) 
> ```
>
> 在获取多个锁时，通过简单的技巧，就可以确保简单有效的无死锁实现。



**有必要对所有的锁进行排序吗？**

如果两组锁不可能在同一个操作中被acquire，那么这两组锁的排序是完全独立的。所以没有必要对所有的锁进行一个全局的排序，但是所有的函数需要对共同使用的一些锁进行一个排序。



## 问题 4 如何实现锁 ？

锁的特性就是只有一个进程可以获取锁，在任何时间点都不能有超过一个锁的持有者。

下面给出一个有问题的 acquire 实现

可以看到这个 acquire 是个死循环，内部会判断当前锁是否有持有者，如果没有的话就获取锁，设置 locked = 1 并返回，否则程序就一直自旋

```c
struct lock {
    int locked; 
};

acquire(l) {
    while(1){
        if(l->locked == 0){ // A
            l->locked = 1; // B
            return;
        }
    }
}
```



问题在哪呢？这个代码存在竞态条件（B处），无法在多处理器上保持互斥

可能会发生两个CPU同时到达 A 处，看到`l->locked`为零，然后都通过执行 B 占有锁。此时就有两个不同的CPU持有锁，从而违反了互斥属性。我们需要的是一种方法，使第5行和第6行作为原子（即不可分割）步骤执行。

那么如何消除竞态条件呢？锁可以消除竞态条件，但是我们现在就是要实现一个锁啊！这不成了鸡和蛋的问题了吗？

为了解决这里的问题并得到一个正确的锁的实现方式，其实有多种方法，但是最常见的方法是依赖于一个特殊的硬件指令。这个特殊的硬件指令会**保证一次test-and-set操作的原子性**。（RISC-V 上就是 amoswap，atomic memory swap)



> 不同处理器的具体实现可能会非常不一样，处理器的指令集通常像是一个说明文档，它不会有具体实现的细节，具体的实现依赖于内存系统是如何工作的，比如说：
>
> * 多个处理器共用一个内存控制器，**内存控制器**可以支持这里的操作，比如给一个特定的地址加锁，然后让一个处理器执行2-3个指令，然后再解锁。因为所有的处理器都需要通过这里的内存控制器完成读写，所以内存控制器可以对操作进行排序和加锁。
> * 如果内存位于一个共享的总线上，那么需要**总线控制器（bus arbiter）来支持**。总线控制器需要以原子的方式执行多个内存操作。
> * 如果处理器有缓存，那么**缓存一致性协议**会确保对于持有了我们想要更新的数据的cache line只有一个写入者，相应的处理器会对cache line加锁，完成两个操作。
>
> 硬件原子操作的实现可以有很多种方法。但是基本上都是对于地址加锁，读出数据，写入新数据，然后再返回旧数据（注，也就是实现了atomic swap）。



### 指令顺序与内存屏障
