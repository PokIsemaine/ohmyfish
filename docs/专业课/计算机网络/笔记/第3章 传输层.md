# 第3章 传输层

## 3.1 概述和传输层服务

### 传输服务和协议

传输层向上提供的服务：进程与进程之间 以报文 message 为单位的 逻辑通信

逻辑通信：看起来两个远程应用之间通过 socket API 直接通信了，实际上还是要一层层传过去的



TCP 把上面传下来的 message 下来分成若干 segment ，借助网络层提供的服务传到远程的对等 TCP 实体（具体如何做，可以看后面的网络层，目前先假设网络层提供这样的服务），然后 TCP 再把分散的 segment 拼接成 message



TCP 是流的协议，保证流是正常的，不保证报文的界限，需要应用层来标识哪里是开始哪里是结束

[tcp的传输过程是可靠的，那为什么许多较大的下载最终还要校验文件完整性？](https://www.zhihu.com/question/532373054/answer/2493042170)



有多个传输层可供选择：TCP 和 UDP



![image-20220606230120473](https://s2.loli.net/2022/06/06/9d5huHwFsJaB2ly.png)



### 传输层 vs 网络层

传输层向上提供的服务相较网络层向上提供的服务做了加强

网络层（IP）提供的服务：丢失、乱序、延迟

传输层（TCP）可以弥补网络层的不足，向上层提供可靠的服务 RDT



传输层还提供了在源端复用 TCP 实体并在目标端 解复用的重要功能，这是网络层不具备的。

实际上就是传输层相比网络层做了更细的划分，网络层是主机到主机，传输层是进程到进程



注意有些东西是 TCP 加强不了的 TCP 并不能降低延迟、也不能提升带宽

TCP 本身不保证安全性，不过可以使用 SSL 来保证安全性

![image-20220606231428334](https://s2.loli.net/2022/06/06/TtNczH3Ip26DryE.png)

### Internet 传输层

![image-20220606231843673](https://s2.loli.net/2022/06/06/Az2HgyjRZ8YKeGV.png)



## 3.2 多路复用和解复用

先前提到多路复用和解复用实际上就是传输层在网络层基础上的进一步细分：从主机到主机细分为进程到进程



![image-20220606233151475](https://s2.loli.net/2022/06/06/tiGuOQndwW5l6Ps.png)



### 多路复用解复用工作原理

那么如何区分同一主机的不同进程呢？这正是解复用要做的。

主机联合使用 IP 地址和端口号将报文段发送给合适的套接字



![image-20220607083715362](https://s2.loli.net/2022/06/08/glWyxFAQEtHkJnY.png)



关于端口 https://zhuanlan.zhihu.com/p/280672302



### 无连接的多路解复用

2元组：目标 IP ， 目标端口号

两个不同源 IP 地址/源端口号的数据报具有相同的目标 IP 和端口号就会被定位到相同的套接字

![image-20220607085337760](https://s2.loli.net/2022/06/08/BlbDwjkIy3aCKve.png)



### 面向连接的多路解复用

TCP 4 元组：源 IP，目标 IP，源端口号，目标端口号

任意一项不同就会被定位到不同的套接字

![image-20220607085057778](https://s2.loli.net/2022/06/08/ml6wdyM2DeScorz.png)

为什么 TCP 要四元组 https://blog.csdn.net/yxg520s/article/details/121379245



### 面向连接的多路复用：多线程 Web Server

![image-20220607085548114](https://s2.loli.net/2022/06/08/uNCDaVP4vHGI3nQ.png)

连接套接字与进程之间并非总是有着一一对应的关系



## 3.3 无连接传输 UDP

UDP : User Datagram Protocol  用户数据报协议

尽力而为 = 能搞就搞，搞不定拉到

![image-20220607090019649](https://s2.loli.net/2022/06/08/pwr96G5SYeMnk32.png)



### UDP：用户数据报协议

为什么要使用 UDP

* 无连接减少延迟
* 头部小只有八字节（源端口号、目的端口号、长度、校验和）开销小，TCP 的话有二十字节，开销要大很多
* 由于没有拥塞控制和流量控制：应用 message 往下传输的速率和主机到网络中的传输速率基本是一致的（下图 V1=V2）上面来多快，下面就发多快，不考虑对方还有网络堵不堵



<img src="https://s2.loli.net/2022/06/08/6PczYJ8VKmQLRop.png" alt="image-20220607091354467" style="zoom:80%;" />



这些特性使得 UDP 很适合一些实时性的应用



![image-20220607090558046](https://s2.loli.net/2022/06/08/rtovVPaz7kjUe1T.png)





### UDP 校验和

![image-20220607091613412](https://s2.loli.net/2022/06/08/IGlrTYsK7bz4muP.png)

如果校验失败会直接被丢弃



**通过校验不等于没有差错**：残存错误

接收方校验实际上是校验：校验和是否和字段内容匹配

如果校验和与字段内容同时出错但又恰好匹配，那么错误的数据就会通过校验



UDP 校验和保护的范围不止是数据部分，还会包含 UDP 的头部以及一些 IP 尾部



![image-20220607092742799](https://s2.loli.net/2022/06/08/4DCyqV1LN7Inuha.png)



<img src="https://s2.loli.net/2022/06/08/8cb4igOEUd9Mp72.png" alt="image-20220607093130714" style="zoom:80%;" />



## 3.4 可靠数据传输的原理

可靠数据传输：RDT

可靠数据传输可以在不同层实现，而 TCP 只是传输层可靠数据传输的典型代表，了解原理可以帮助我们快速学习其他层可靠数据传输的实现



rdt 问题的复杂性：要向上层提供可靠的服务，然而依赖的服务却并不可靠

> 映射到现实里其实就是中间管理层的难处啦。团长（当前层）要向师长（上层）保证坚决完成任务（提供可靠服务），然而团长（当前层）下面的连长（依赖层）表示会尽力而为（提供尽力而为的、不可靠的服务）



### 可靠数据传输：问题描述

![image-20220607094449753](https://s2.loli.net/2022/06/08/3wDU4MRWA6O8FbQ.png)

我们的方法论如下：

* 渐进式地开发：逐个把假设去掉，逐步接近真实情况，然后增加机制对抗不可靠性
* 只考虑单向数据传输：双向的数据传输实际上就是 2 个单向数据传输问题的综合
	* 不过要记住控制信息是双向流动的（会有一些反馈信息）
* 使用有限状态机 FSM 来描述发送方和接收方



### Rdt 1.0：在可靠信道上的可靠数据传输

假设：信道完全可靠，不出错、不丢失

发送方：

1. **接收**上层调用来的数据单元
2. 将上层数据单元**封装**为本层的数据单元
3. **发送**本层的数据单元

接收方：

1. **接收**下层调用来的数据单元
2. 将下层数据单元**解封装**为本层的数据单元
3. **发送**本层的数据单元



> rdt 1.0 映射到现实就是连长很能干，团长啥都不用干



![image-20220607095422693](https://s2.loli.net/2022/06/08/9Modc8IQSFRzPfr.png)



### Rdt 2.0：具有比特差错的信道

假设：信道不会丢失，但可能出现比特差错



![image-20220607100148717](https://s2.loli.net/2022/06/08/x5MfnEdbuCPABZT.png)

> rdt2.0 可以类比老师给学生讲题：老师讲一遍题，学生反馈懂没懂。
>
> 学生懂了，那就跟老师反馈懂了。然后学生开始做这题，老师开始等待下一题。
>
> 学生没懂，就和老师反馈没懂，老师接收到没懂的反馈后重新讲一遍题并和先前一样等待学生的反馈



![image-20220607101057170](https://s2.loli.net/2022/06/09/ARkCHxF6PaiwYQu.png)







![image-20220607101945493](https://s2.loli.net/2022/06/08/O5GjsWvIkordRPH.png)

### Rdt2.0 的致命缺陷！-> Rdt 2.1

![image-20220607102541346](https://s2.loli.net/2022/06/08/SrC36JayBpiLIHO.png)



rdt2.0 已经考虑了 packet 出错的可能，那么如果 ACK 或者 NAK 出错呢

![image-20220607102248909](https://s2.loli.net/2022/06/08/NHpOTqulbsrdv4G.png)



为了应对 ACK 或者 NAK 可能出现问题的情况，rdt 2.1 引入了新的机制：识别不了反馈就重发并且给分组加序号

简单来说就是如果受到了莫名奇妙的反馈那就把原来的 package 重发一遍，这有可能造成重复，所以我们对分组进行编号这样可以把受到的重复分组丢掉了



![image-20220607103249352](https://s2.loli.net/2022/06/08/H3dIlTLoY7ywmSP.png)

发送方处理出错的 ACK/NCK

![image-20220607103808408](https://s2.loli.net/2022/06/08/xaipsVjrO6JqTAn.png)

接收方处理出错的 ACK/NAK

![image-20220607103915158](https://s2.loli.net/2022/06/08/qb7KAxXt5yVg2NC.png)



发送方

* 在分组中加入序列号，**两个序列号(0,1)就够了，因为目前还是停等协议**（发送方发送一个分组， 然后等待接收方的应答，一次只发送一个未经确认 的分组）
* 必须检测 ACK/NAK 是否出错（需要 EDC）
* 状态数变成了两倍，必须记住当前分组的序列号为0还是1

接收方

* 必须检测接收到的分组是否重复，状态会指示希望接收到 0 还是 1
* 接收方并不知道发送方是否正确接收到了ACK/NAK，没有安排确认的确认，因为这样会无限套娃（确认的确认的确认……），接收方通过发送方后续的行为表现来判断

![image-20220608225550524](https://s2.loli.net/2022/06/08/v86UXiM4qmSeJFT.png)

### Rdt 2.2 无 NAK 的协议

![image-20220608230115389](https://s2.loli.net/2022/06/08/5gc2DLQ8TliwmGt.png)



> 女："你觉得我漂亮吗？"
>
> rdt2.1 版本男："你不漂亮" 
>
> rdt2.2 版本男："你很温柔"
>
> 理解这个对话就能理解 rdt2.2 的实质：巧妙地回答 否定含义
>
> 由此可见 rdt2.1 是低情商版本，rdt2.2 是高情商版本





原来的每次一个 ACK 需要对应一个 NACK

| ACK0 | ACK1 | ACK2 | ……   |
| ---- | ---- | ---- | ---- |
| NAK0 | NAK1 | NAK2 |      |

但实际上对于 ACK1 而言其对应的 NAK1 和 ACK0 是等价的，同理

ACK0 = NAK1，ACK1 = NAK2，……

也就是说我们可以用前一个的 ACK 代替当的 NAK



![image-20220608230414166](https://s2.loli.net/2022/06/08/w3Uxd1v8QWe65cR.png)

![image-20220608231531199](https://s2.loli.net/2022/06/08/nwAxUhokjPTzJly.png)



红色为和 rdt2.1 不同的地方

![image-20220608231546846](https://s2.loli.net/2022/06/08/CkFR4d2Ums1EnhJ.png)



### Rdt3.0：具有比特差错和分组丢失的信道

新的假设：下次信道可能会丢失分组（数据或 ACK）

这会造成死锁的情况（见下图，只是展现了数据丢了的情况，ACK 也会丢的）

![image-20220608232332688](https://s2.loli.net/2022/06/08/e67kjyN958xSn3V.png)

当前的机制：检验和、序列号、ACK、重传，这还处理不了这种情况，我们需要新机制：超时重传！



![image-20220608233247444](https://s2.loli.net/2022/06/08/RyTGrwh3eZl9ozY.png)



那么如何设置合理的 timeout 时间呢？（具体可以看 TCP 超时时间设置）

在数据链路层两个网卡中间的一段链路，如果延迟分布比较集中，那么可以设为一个确定的时间

如果两台主机（传输层）经过了很多路由器连接，网卡延迟变化比较大，那么就自适应地去算 timeout



![image-20220608234702983](https://s2.loli.net/2022/06/09/tBujSYxA3neUO62.png)





状态机

![image-20220609195344131](https://s2.loli.net/2022/06/09/jXS9MNIdkhTqOw2.png)



rdt3.0 的运行

一般来讲 timeout 的设置是大于正常接收 ACK 时间的，但是如果 timeout 设置不合理造成过早超时，那么 rdt3.0 的效率会降低，一半的分组是重复的

![image-20220609195730152](https://s2.loli.net/2022/06/09/ouGwtET7WanvOml.png)





| 可靠数据传输 | 假设 | 机制 |
| ------------ | ---- | ---- |
| rdt1.0       |      |      |
| rdt2.0       |      |      |
| rdt2.1       |      |      |
| rdt2.2       |      |      |
| rdt3.0       |      |      |



rdt3.0 的性能问题：停-等操作的 rdt3.0 会在链路容量比较大的情况下产生性能问题

> 这就好比从浙江到哈尔滨有一条很宽很长的高速公路，停等操作相当于这条路每次只能通行一辆车，一辆车可能要很久很久才能到达，到达的信息返回又要很久很久，这就造成了极大的浪费。这是协议本身的问题

![image-20220609201150261](https://s2.loli.net/2022/06/09/i1q6RwOBDzt7Lao.png)





### 流水线协议

如何增加利用率？一次发多个并且现在要好几个编号了，这就是流水线技术

![image-20220609212001184](https://s2.loli.net/2022/06/09/mrGNOtUz93iSVFW.png)



停等协议适合局域网、链路容量比较小的情况。在链路容量比较大的情况下可以采用流水线技术，流水线技术一次发送多个未确认的分组，解决了协议瓶颈提高了利用率并无限接近 100%，再提升很难了，现在瓶颈变为了链路带宽



为了实现流水线技术需要一些新东西

* 必须增加序号的范围：用多个 bit 表示分组的序号（原来只要 1 位 bit 即可）
* 在发送方/接收方要有缓冲区（why？）
	* 发送方缓冲：未得到确认，可能需要重传
	* 接收方缓冲：上层用户取数据的速率和接收到的数据速率不同；接收到的数据可能会乱序，排序交付

![image-20220627101118783](https://s2.loli.net/2022/06/27/QqV7bFrwauz4PkZ.png)



### 滑动窗口协议

在了解通用的流水线协议（回退N步和选择重传协议）之前先来了解一下 通用的滑动窗口协议

根据缓冲区（窗口）大小可以对滑动窗口协议进行如下划分，其中 GBN 和 SR 是两种通用的流水线协议

| 协议         | 发送窗口 | 接收窗口 |
| ------------ | -------- | -------- |
| 停止等待协议 | =1       | =1       |
| 回退N步 GBN  | >1       | =1       |
| 选择重传 SR  | >1       | >1       |

**发送窗口**

![image-20220627101221402](https://s2.loli.net/2022/06/27/d6Qo8A41etJwzhL.png)

![image-20220627101548342](../../../../../../.config/Typora/typora-user-images/image-20220627101548342.png)

![image-20220627101612111](https://s2.loli.net/2022/06/27/jPHAx5rhu4kzOL3.png)

发送窗口前沿移动

* 每发送一个分组，前沿前移一个单位

* 发送窗口前沿移动的极限：不能够超过发送缓冲区

发送窗口后沿移动

* 条件：收到老分组的确认 
*  结果：发送缓冲区罩住新的分组，来了分组可以发送 
* 移动的极限：不能够超过前沿

![image-20220627102120781](https://s2.loli.net/2022/06/27/67nvNq53gbT49AM.png)



**接收窗口**

![image-20220627102530196](https://s2.loli.net/2022/06/27/LDnWOkTwlcGMvB8.png)

接收窗口滑动和确认

![image-20220627104349878](https://s2.loli.net/2022/06/27/rVngPqTYHCG46vp.png)

![image-20220627104513076](https://s2.loli.net/2022/06/27/R5QHgLxy1oIDeMW.png)

**两个窗口的互动**

![image-20220627104946995](https://s2.loli.net/2022/06/27/eF2hyAo3ZXuTMrD.png)

![image-20220627105007044](https://s2.loli.net/2022/06/27/4bMOVpX7nx25PAN.png)



### GBN 与 SR

![image-20220627105315440](../../../../../../.config/Typora/typora-user-images/image-20220627105315440.png)



![image-20220627124742609](https://s2.loli.net/2022/06/27/6nraesLPo9xgGRZ.png)



**GBN FSM**

![image-20220627125546717](https://s2.loli.net/2022/06/27/pHnYvdBXhx6CVZM.png)

![image-20220627153112783](https://s2.loli.net/2022/06/27/S2LEVTxcMuyWG5B.png)

**选择重传**

![image-20220627153135745](https://s2.loli.net/2022/06/27/VsCYh1nNWz37vxA.png)

![image-20220627153230629](https://s2.loli.net/2022/06/27/3Xe1GuPtWqmvTQk.png)

![image-20220627153251275](https://s2.loli.net/2022/06/27/4naItvy8MfqhsUB.png)

TIP：上图左侧黑色框是发送缓冲区范围，不是发送窗口范围，发送窗口大小和接收窗口大小都是4

**对比GBN和SR**

![image-20220627153319083](../../../../../../.config/Typora/typora-user-images/image-20220627153319083.png)



**思考题：窗口的最大尺寸**

如果 n 来代表分组的序号，GBN 协议窗口最大尺寸$2^n-1$，SR 协议窗口最大尺寸 $2^{n-1}$，如果超过了这个最大尺寸会发生什么？

![image-20220627154425066](../../../../../../.config/Typora/typora-user-images/image-20220627154425066.png)



## 3.5 面向连接的传输：TCP

### TCP 概述

![image-20220630153529584](../../../../../../.config/Typora/typora-user-images/image-20220630153529584.png)

TCP 特点

* 点到点：一个应用进程到另一个应用进程的服务，不提供一点到多点和多点到多点的服务

* 可靠的、按顺序的字节流

	* 不出错、不重复、不失序、不丢失
	* 但是不提供报文的界限。交两个报文可能收两个大一点的报文，可能收到四个小一点的报文。报文的界限需要应用进程自己去维护

* 管道化（流水线）

	* 发送方在未经确认的情况下可以连续发送很多 TCP 报文段

* 发送和接收缓冲区

	* 发送方：检错重发、超时重传
	* 接收方：读取速率和发送方发送速率不一直，需要做速度匹配

* 全双工数据：

	* 发给对方的时候，对方也可以往下传给自己，是同时双向的

	* MSS：最大报文段大小，应用层交的报文如果非常大，往下传的时候加TCP头部、网络层头部等，到最后没法封装在一个物理网络帧的载荷部分。

		* 每个物理网络有一个 MTU 最大传输单元（例如以太网 1500 MB 
		* 关于 MTU 看这个 https://info.support.huawei.com/info-finder/encyclopedia/zh/MTU.html

		



![image-20220630160534802](https://s2.loli.net/2022/06/30/nChiUvIf1Fr26sj.png)

### 段结构

![image-20220630160721486](https://s2.loli.net/2022/06/30/pKyvHmiQ9TRz6sO.png)

**TCP 序号**

报文段首字节在字节流的编号（（字节流根据 MSS 分成 TCP 段， TCP 段包含 头部和 Body 载荷部分，Body载荷部分第一个字节在整个字节流中的偏移量就是 TCP 序号）

两个应用进程通过 TCP 握手连接的时候商量好一个初始的序号（下图中从 X 开始）

为什么不从 0 或者 1 固定序号开始呢？为了防止老连接的滞留在网络中的 TCP 段对新的连接造成影响



![image-20220630161550699](https://s2.loli.net/2022/06/30/Ggasj8McyEbuL7n.png)



**TCP 确认号**

![image-20220630161956690](https://s2.loli.net/2022/06/30/JsgEdrZDy6FIRAv.png)



累计确认：如果发送方收到接收方 ACK = 555，那么说明已经收到 554 之前（包括554）的



![image-20220630162944041](https://s2.loli.net/2022/06/30/rBXE5yR8NAb1to4.png)

### TCP 往返延时（RTT）和超时

![image-20220630193826561](https://s2.loli.net/2022/06/30/aFKUMwS8kTeBDLq.png)

两个应用进程距离可能很近，也可能很远。大洋两岸的两个应用进程之间会有很多跳板，这造成了较长一段时间内两者的往返延时 RTT 分布较为分散，这导致我们难以确定一个合适的超时时间。

但是在较短时间内，二者的 RTT 分布是较为集中的，确定超时时间比较容易。

![image-20220630193740583](https://s2.loli.net/2022/06/30/YmSKTvAQzLxep2i.png)

这说明 TCP 的网络环境在一天中的某些时间段非常大，很难确定一个固定的超时时间来适应所有情况（相较局域网而言的，局域网是相对稳定的，可以采用一个固定的超时时间）



所以超时时间应该自适应的进行调整

**第一步就是要测量往返延时**

![image-20220630194503430](https://s2.loli.net/2022/06/30/fTB6eAqHadIjZPz.png)

采样得到的$SmapleRTT$ 会变化，因此估计的 $RTT$ 会相对平滑，要对最近几次的测量值求平均

设当前时间段采样的$SampleRTT$ 对平均时间贡献加权为 $\alpha$

设前一时间段采样的$SampleRTT$ 对平均时间贡献加权为 $1-\alpha$

设再前一时间段采样的$SampleRTT$ 对平均时间贡献为 $（1-\alpha)^2$

以此类推，距离当前时间越远，采样值对平均值贡献越来越小

归纳一下就是$EstimateRTT = (1-\alpha) * EstimateRTT + \alpha * SampleRTT$



**第二步就是设置超时时间**

考虑两点

* 平均 RTT 越大，超时时间越大
* 平均 RTT 变化越大，超时时间越大

为了得到变化程度，需要计算 $SampleRTT$ 会偏离 $EstimatedRTT$ 多远 

![image-20220630195146078](../../../../../../.config/Typora/typora-user-images/image-20220630195146078.png)



### 可靠数据传输

![image-20220704195922762](https://s2.loli.net/2022/07/04/sDGRW2qcE7FCfLT.png)



![image-20220704200225318](https://s2.loli.net/2022/07/04/BfsSuo9E5RrqPvD.png)



**TCP 发送方事件**

从应用层接收数据

* 用`nextseq`创建报文段 
* 序号`nextseq`为报文段首字 节的字节流编号 
	* 如果还没有运行，启动定 时器 定时器与最早未确认的报文 段关联 
	* 过期间隔： `TimeOutInterval`

超时

* 重传后沿最老的报文段 
* 重新启动定时器

收到确认

* 如果是对尚未确认的报文段确认 
	* 更新已被确认的报文序号 
	* 如果当前还有未被确认的报文段，重新启动定时器



简化的TCP发送方伪代码

```c
NextSeqNum = InitialSeqNum
SendBase = InitialSeqNum
loop (forever) {
    switch(event) 
        event: data received from application above
    		create TCP segment with sequence number NextSeqNum
    		if (timer currently not running) 
                start timer
            pass segment to IP
    		NextSeqNum = NextSeqNum + length(data) 
                
        event: timer timeout 
            retransmit not-yet-acknowledged segment with
    			smallest sequence number 
        start timer 
           
        event: ACK received, with ACK field value of y
    	if (y > SendBase) {
            SendBase = y
            if (there are currently not-yet-acknowledged segments) 
                start timer 
        }
} /* end of loop forever */
```

### 重传

![image-20220704203915121](https://s2.loli.net/2022/07/04/DZHcu6MgtX73VU9.png)

**ACK 丢失**

Seq = 92，8个字节，则 99 是顺序到来的最后一个字节，说明 99 及以前的都已经收到了，接收方希望发送方从 100 开始传 ACK = 100（ACK = 顺序到来的最后一个字节+1 = 期待发送方下次发的）

如果发送方没收到 ACK = 100 则超时重传



**过早超时**

发送方发送了 92.8 和 100.20，接收方 返回 ACK =100 和 ACK = 120

但此时定时器出现问题过早超时，在 ACK 到达之前超时了，只会发 92.8

这个时候接收方返回的 ACK 是顺序到来的最后一个字节  + 1，接收方先前已经收到 92.8 和 100.20 所以返回 ACK = 120

**这个实际上就体现了 TCP 接收方发送的确认是累计确认**（可以结合下面两幅图）

![image-20220704203941126](https://s2.loli.net/2022/07/04/95GenPmIqaUxHtl.png)

这种累计、延迟的手法有利于提高效率、减少对发送方的干扰

![image-20220704204203146](https://s2.loli.net/2022/07/04/9OGfdaF12EHXSLu.png)

对应四种情况，简单的概括就是

* 接收方缺什么 ACK 就是什么
* 使用累计和延迟技巧提高效率减少对发送方干扰

![image-20220704205834490](https://s2.loli.net/2022/07/04/AO69zjFsJR1DStx.png)



**快速重传**

![image-20220704210235412](https://s2.loli.net/2022/07/04/VkrZg4Y8pMOQzBE.png)



![image-20220704222336376](https://s2.loli.net/2022/07/04/6vNLoZtw1Bxrz9a.png)



```c
event: ACK received, with ACK field value of y
    if (y > SendBase) {
        SendBase = y
        if (there are currently not-yet-acknowledged segments)
        start timer
    }
    else {	//已确认报文段的一个重复确认
        increment count of dup ACKs received for y
        if (count of dup ACKs received for y = 3) {
        	resend segment with sequence number y	//快速重传
        }
```



### 流量控制

流量控制：接收方控制发送方，不让发送方发送的太多、太快以至于让接收方的缓冲区溢出

![image-20220704222937538](https://s2.loli.net/2022/07/04/dyjboiCI7Wrkuwm.png)

把接收方缓冲区还剩的空间反馈给发送方就可以啦

方法：捎带技术 Piggybacking 把空闲的尺寸反馈给发送方

![image-20220704223336030](../../../../../../.config/Typora/typora-user-images/image-20220704223336030.png)

![image-20220704223415671](../../../../../../.config/Typora/typora-user-images/image-20220704223415671.png)

### 连接管理

**连接建立**

连接建立的本质

* 知道要和对方通信
* 准备好资源
* 控制变量置位（连接初始序号、缓冲区大小）

![image-20220704223531525](https://s2.loli.net/2022/07/04/A6ZW1rv35YCHny4.png)

众所周知 TCP 连接建立需要三次握手，那么两次握手为什么不行呢？

![image-20220704224008252](https://s2.loli.net/2022/07/04/1YDahxwL2kVovZd.png)

2次握手的失败场景

* 服务器建立大量虚假半连接
* 老数据被当成新数据接收

![image-20220704224531381](https://s2.loli.net/2022/07/04/GxPkKnZA9uOyvJ3.png)

那么是否至少为三次连接呢？实际上可以想想双方确认初始序号

1. A 告诉 B 自己要从序号 x 开始传
2. B 回复确认
3. B 告诉 A 自己要从序号 y 开始传
4. A 回复确认

这是 4 次握手，但是实际上我们发现 2,3 B 可以放在一起发送，所以只需要 3 次握手即可

实际上第三次握手还往往跟第一次数据传递放在一起

![image-20220704225230301](https://s2.loli.net/2022/07/04/6aQGPIuqk45W3of.png)

3 次握手解决了 2次握手的 半连接问题和接收老数据问题

* 半连接问题：由于三次握手，所以连接关闭后服务器收到客户端重发的老连接请求后想客户端发送确认，客户端发现这是个老的请求拒绝了服务器的热情邀请
* 接收老数据问题：未收到数据确认，超时重发数据后连接关闭了，服务器收到数据但现在服务器和客户端直接爱你已经没连接了直接扔掉，也有可能建立了新的连接，**但是由于每次连接确定的初始序号不同，所以判断这个数据不是这次连接里的，也直接丢掉**（初始序号好像可以根据时钟周期的选择当前时刻的32位来生成）

> 老数据：皇上有旨。。。
>
> 服务器：大人时代变啦！大清已经亡了！

![image-20220704225532641](https://s2.loli.net/2022/07/04/5pO4alzemETSFuQ.png)



![image-20220704231005885](https://s2.loli.net/2022/07/04/6Df41qiEOspNIXn.png)



**连接释放**

把 TCP 的连接分为两个方向，每个方向单独拆除，一方发送连接拆除，另一方发送确认，就拆掉了一个方向的连接

![image-20220704231824593](https://s2.loli.net/2022/07/04/JOkWzv2EFI1ZnY5.png)



![image-20220704231838598](https://s2.loli.net/2022/07/04/TvkjtaCz4y5XSLp.png)



两次交互确认完美吗？不完美，存在两军问题：确认的确认的确认。。。。可以用定时器来解决一下 TIME_WAIT ?

https://zhuanlan.zhihu.com/p/51936795

> 但是理论上无解的问题，工程上依然可以给出一个足够好的解决方案。
>
> 解决两军问题的工程思路就是接受不确定性这个事实，但是努力把不确定性控制到一个可以接受的程度。例如，我们可以让将军 A1 发出一百个信使送信，那么信使全部都被抓住的可能性就很小了。这样，A1 自己决定进攻，A2 只要收到哪怕一个信使的信息也会进攻。这就是一个足够好的解决方案了。
>
> 工程上，TCP 协议需要三次握手来建立连接，也是为了降低不确定性。但是总体而言，TCP 是不完全可靠的协议，所以互联网是一个不完全可靠的网络。



## 3.6 拥塞控制原理

![image-20220704232929489](https://s2.loli.net/2022/07/04/n9vuPoTBDpR8Hl2.png)

### 拥塞的原因/代价

**场景一**

![image-20220704233502437](https://s2.loli.net/2022/07/04/Im3neGiyZOE85rQ.png)

数据太多超出网络承载能力了，虽然在场景一中数据的吞吐拉满了，但是当进入的速率接近链路带宽的时候（流量强度接近1）**延迟也越来越大了**



**场景二**

![image-20220704233637429](../../../../../../.config/Typora/typora-user-images/image-20220704233637429.png)

一、场景二的理想化情况

![image-20220704233719506](https://s2.loli.net/2022/07/04/zsHxuArWR9ZTJDp.png)



![image-20220704233737090](https://s2.loli.net/2022/07/04/7IYOyjN2ler6AaW.png)



![image-20220704233800062](https://s2.loli.net/2022/07/04/Od5Sr8zW4klKeQB.png)

在场景二的理想情况中，掌握了丢失信息，分组丢失可以重传。那么随着网络拥塞程度增加，分组丢失率增加，那么实际传送的分组中就会包含一部分重传的分组

并且会越多，这意味着有效的迸出越来越少了



二、场景二的现实情况

![image-20220704233841500](../../../../../../.config/Typora/typora-user-images/image-20220704233841500.png)

![image-20220704233901404](../../../../../../.config/Typora/typora-user-images/image-20220704233901404.png)

在现实情况中除了重传的丢失分组，还会包含没有必要重传的重复分组

一部分分组被存在路由器缓冲中，网络拥塞，延迟加大，接收方一直没收到然后给确认，所以发送方超时重发了。然而实际上这些分组只是滞留在了路由器中排队等待，并没有丢失，发送方超时重发来的分组就会造成重复



场景三：网络拥塞达到极致：网络死锁了

![image-20220704233943034](https://s2.loli.net/2022/07/04/EcznPb1YkIUqw6B.png)

![image-20220704233958128](https://s2.loli.net/2022/07/04/RcWLkP61Zyvux2S.png)







总结一下拥塞的代价

* 网络延迟大
* 为了让网络得到一个有效的迸出需要更多的迸入速率
* 传输不必要重传的重复分组会加剧拥塞，加速变坏，不控制的话会失控
* 当分组丢失时，任何"关于这个分组的上游传输能力"都被浪费了

所以需要拥塞控制



### 拥塞控制方法

实际上拥塞控制的主要目的就是在网络不发生拥塞的情况下尽可能提高发送速率（不拥塞和提高发送速率是有点矛盾的）

![image-20220705000814248](https://s2.loli.net/2022/07/05/AaX6oDJltVvymMb.png)

端到端拥塞控制: 

*  没有来自网络的显式反馈 
* 端系统根据延迟和丢失事件推断是否有拥塞
* TCP采用的方法

网络辅助的拥塞控制: 

* 路由器提供给端系统以 反馈信息 
	* 单个bit置位，显示有 拥塞 (SNA, DECbit, TCP/IP ECN, ATM) 
	* 显式提供发送端可以 采用的速率



### 案例学习：ATM ABR 拥塞控制（网络辅助）

![image-20220706100754840](https://s2.loli.net/2022/07/06/cbJid9Xuh3pyGOl.png)

![image-20220706100811518](https://s2.loli.net/2022/07/06/nxUzRVtKSIy4QbO.png)





![image-20220706143739931](https://s2.loli.net/2022/07/06/soqObn2wga96IYB.png)

## 3.7 TCP 拥塞控制

### 机制

ATM 为例的网络辅助信息拥塞控制虽然效果比较好但是网络的负担和代价会比较大， TCP 采用的是端到端的拥塞控制

![image-20220706101536102](https://s2.loli.net/2022/07/06/56rkXMIYEPRqHUj.png)

### 拥塞感知

![image-20220706101811698](https://s2.loli.net/2022/07/06/bisxAOHTdafrJ2X.png)

### 速率控制方法

![image-20220706102448067](../../../../../../.config/Typora/typora-user-images/image-20220706102448067.png)

![image-20220706102624373](https://s2.loli.net/2022/07/06/p5AwBVtd4SfZYo8.png)



TCP 的拥塞控制和流量控制是一起处理的，拥塞窗口和接收窗口的最小值决定了发送窗口的大小

![image-20220706102708413](https://s2.loli.net/2022/07/06/hzFGHUp9c1XsuBd.png)



### 策略概述

TCP 拥塞控制策略

* 慢启动
* AIMD：线性增，乘性减少
* 超时事件后的保守策略



**慢启动**

![image-20220706103415630](https://s2.loli.net/2022/07/06/SqAFmIarfLjJ5QN.png)

![image-20220706103706568](https://s2.loli.net/2022/07/06/ZQHtBP72WKN9wc8.png)

**AIMD**

![image-20220706103839717](https://s2.loli.net/2022/07/06/QMY7PJ8dsv5KmVr.png)

![image-20220706103909655](https://s2.loli.net/2022/07/06/U6cyzLskJRGopfi.png)

![image-20220706104037464](https://s2.loli.net/2022/07/06/LtiU4zFGRQEdeSa.png)

![image-20220706104100853](https://s2.loli.net/2022/07/06/cM5Fqe1WRzSJw6P.png)



> 奇妙比喻来啦
>
> A 请 B 到家里喝酒，不过由于不清楚酒量所以要试探一下（假设喝的酒不累计，醉不醉由单次喝酒杯数决定）
>
> 第一次：B 喝了 1杯，2杯，4杯，8杯，16杯（倒了）
>
> 第二次  : A 知道 B 喝 16杯就倒下了，所以这次决定在一半的时候也就是 8 杯的时候让 B 慢点喝
>
> 第二次：B 喝了 1杯，2杯，4杯，8杯；这时候 A 说，哥们你得慢点喝了；B 接下来喝了 9 杯，10 杯（开始胡言乱语了，但还没倒）A 说：哥们你醉了吧，今就喝到这
>
> 第三次：A 说：哥们上次你喝了 10 杯就开始胡言乱语了，不尽兴啊，这次直接 5杯开干；B 喝了 5 杯，6杯，7杯 。。。。
>
> 

![image-20220706105213475](https://s2.loli.net/2022/07/06/ReporLn5gSykIsz.png)



**总结拥塞控制**

![image-20220706105300276](https://s2.loli.net/2022/07/06/GyBxf4oRCUwbWng.png)



### 吞吐量

![image-20220706143555131](https://s2.loli.net/2022/07/06/qUQcSiYukF4a51j.png)



### TCP 未来：TCP over “long,fast pipes”

![image-20220706143628113](https://s2.loli.net/2022/07/06/Jgwn5qGTicv1BRf.png)

### 公平性

两个竞争的 TCP会话获取带宽基本上是公平的

![image-20220706105932511](https://s2.loli.net/2022/07/06/FV2PSiLmuHKEe9d.png)



![image-20220706110006019](https://s2.loli.net/2022/07/06/PJTHZY2rORWNaiS.png)

假设往返延迟 $RTT_{AA'}=RTT_{BB'}$，然后见下图

![image-20220706142900026](https://s2.loli.net/2022/07/06/24d6k1MEIjebpVr.png)

不公平的情况

* 如果 A-A' 用了 UDP 连接，那就不公平了，UDP 想发多快发多快，并且具有侵略性，UDP 对 TCP 不友好
* 如果 B-B' 已经有 9 个 TCP 连接了，A-A’ 建立一个连接，从主机角度看 B-B‘ 获得了 9/10 的带宽，这样也不公平
* 如果 A-A‘ 和 B-B’都是 1 个 TCP 连接，但是 $RTT_{AA'} < RTT_{BB'}$ 那也不公平了

![image-20220706143658590](https://s2.loli.net/2022/07/06/dFBIGl91yvVhPmq.png)



## 第三章 总结

![image-20220706143816909](https://s2.loli.net/2022/07/06/R438nOcB57qK92b.png)

![image-20220706143841493](https://s2.loli.net/2022/07/06/pwLXgKk2bYcJdmH.png)
